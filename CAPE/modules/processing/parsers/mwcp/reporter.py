"""
    DC3-MWCP framework primary object used for execution of parsers and collection of metadata
"""
from __future__ import print_function, unicode_literals

import contextlib

from future.builtins import str, open, map

import base64
import binascii
import hashlib
import json
import ntpath
import logging
import os
import re
import shutil
import sys
import tempfile
import warnings

import mwcp
from mwcp import resources
from mwcp.utils.stringutils import convert_to_unicode
from mwcp.utils import logutil


logger = logging.getLogger(__name__)


PY3 = sys.version_info > (3,)

# pefile is now strictly optional, loaded down below so we can use
# reporter for error reporting

INFO_FIELD_ORDER = ['inputfilename', 'md5', 'sha1', 'sha256', 'compiletime']
STANDARD_FIELD_ORDER = ["c2_url", "c2_socketaddress", "c2_address",
                        "proxy", "proxy_credential", "proxy_username", "proxy_password",
                        "proxy_socketaddress", "proxy_address", "proxyport",
                        "url", "urlpath",
                        "socketaddress", "address", "port", "listenport",
                        "credential", "username", "password",
                        "missionid", "useragent", "interval", "version", "mutex",
                        "service", "servicename", "servicedisplayname", "servicedescription",
                        "serviceimage", "servicedll", "injectionprocess",
                        "filepath", "directory", "filename",
                        "registrykeyvalue", "registrykey", "registryvalue", "key"]


class ReporterLogHandler(logging.Handler):
    """Custom logging handler used to keep backwards compatible with legacy logging mechanism."""

    def __init__(self, reporter):
        super(ReporterLogHandler, self).__init__()
        self._reporter = reporter

    def emit(self, record):
        message = self.format(record)
        if record.levelno > logging.WARNING:
            self._reporter.errors.append(message)
        # Even though reporter uses the name "debug".. This really is an INFO level debug message.
        # (Adding true DEBUG level messages would spam our console.)
        elif logging.INFO <= record.levelno <= logging.WARNING:
            self._reporter.add_metadata("debug", message)


class Reporter(object):
    """
    Class for doing heavy lifting of parser execution and metadata reporting

    This class contains state and data about the current config parsing run, including extracted
    metadata, holding the actual sample, etc.

    Re-using an instance of this class on multiple samples is possible and should be safe, but it
    is not recommended

    Attributes:
        parserdir:
            Optional extra directory where parsers reside.
        tempdir:
            directory where temporary files should be created. Files created in this directory should
            be deleted by parser. See managed_tempdir for mwcp managed directory
        input_file:
            the original parsed file. (instance of mwcp.FileObject)
        data:
            byte string data of the input_file (DEPRECATED)
        handle:
            file handle (BytesIO) of the input_file (DEPRECATED)
        pe:
            a pefile.PE object of the input_file (if applicable) (DEPRECATED)
        metadata:
            Dictionary containing the metadata extracted from the malware by the parser
        outputfiles:
            dictionary of entries for each output file. The key is the filename specified. Each entry
            is a dictionary with keys of data, description, and md5. If the path key is set, the file was written
            to that path on the filesystem.
        fields:
            dictionary containing the standardized fields with each field comprising an embedded
            dictionary. The 1st level keys are the field names. Under that, the keys are "description",
            "examples", and "type". See fields.json.
        errors:
            list of errors generated by framework. Generally parsers should not set these, they should
            use debug instead

    """

    DEFAULT_PARSERDIR = os.path.dirname(mwcp.parsers.__file__)

    URL_RE = re.compile(r"[a-z\.-]{1,40}://(?P<address>\[?[^/]+\]?)(?P<path>/[^?]+)?")
    PORT_RE = re.compile(r"[0-9]{1,5}")
    SHA1_RE = re.compile('[0-9a-fA-F]{40}')

    def __init__(self,
                 parserdir=None,
                 outputdir=None,
                 tempdir=None,
                 outputfile_prefix=None,
                 interpreter_path=None,
                 disableoutputfiles=False,
                 disabletempcleanup=False,
                 disableautosubfieldparsing=False,
                 disablevaluededup=False,
                 disablemodulesearch=False,
                 base64outputfiles=False,
                 ):
        """
        Initializes the Reporter object

        :param str parserdir: sets parser directory (defaults to parsers found in mwcp/parsers)
        :param str tempdir: sets path to temporary directory
        :param str outputdir:
            sets directory for output_file(). Should not be written to (or read from) by parsers
            directly (use tempdir)
        :param str outputfile_prefix:
            sets prefix for output files written to outputdir. Special value "md5" causes prefix
            by md5 of the input file.
        :param str interpreter_path: overrides value returned by interpreter_path()
        :param bool disableoutputfiles: disable writing if files to filesystem
        :param bool disabletempcleanup: disable cleanup (deletion) of temp files
        :param bool disableautosubfieldparsing: disable parsing of metadata item of subfields
        :param bool disablevaluededup: disable deduplication of metadata items
        :param bool disablemodulesearch: disable search of modules for parsers, only look in parsers directory
        """

        # defaults
        self.tempdir = tempdir or tempfile.gettempdir()
        self.outputfiles = {}
        self._handle = None
        self._log_handler = None
        self.fields = {"debug": {"description": "debug", "type": "listofstrings"}}
        self.metadata = {}
        self.errors = []
        self.input_file = None

        # Continue to allow use of deprecated resourcedir.
        # TODO: Remove this in a new release version.
        self._resourcedir = None
        self.resourcedir = os.path.dirname(resources.__file__)

        self.__managed_tempdir = None
        self.__outputdir = outputdir or ''
        self.__outputfile_prefix = outputfile_prefix or ''

        # Register parsers from given directory.
        self.parserdir = parserdir or self.DEFAULT_PARSERDIR
        mwcp.register_parser_directory(self.parserdir)

        self._interpreter_path = interpreter_path
        self._disable_output_files = disableoutputfiles
        self._disable_temp_cleanup = disabletempcleanup
        self._disable_auto_subfield_parsing = disableautosubfieldparsing
        self._disable_value_dedup = disablevaluededup
        self._disable_module_search = disablemodulesearch
        self._base64_output_files = base64outputfiles

        # TODO: Move fields.json to shared data or config folder.
        fieldspath = os.path.join(os.path.dirname(mwcp.resources.__file__), "fields.json")

        with open(fieldspath, 'rb') as f:
            self.fields = json.load(f)

    # Allow user to still use resourcedir feature, but warn about deprecation.
    @property
    def resourcedir(self):
        warnings.warn(
            'resourcedir feature has been deprecated. Dependencies should be properly installed and managed by the parser developer.', DeprecationWarning, 1)
        return self._resourcedir

    @resourcedir.setter
    def resourcedir(self, resourcedir):
        warnings.warn(
            'resourcedir feature has been deprecated. Dependencies should be properly installed and managed by the parser developer.', DeprecationWarning, 1)
        self._resourcedir = resourcedir
        if resourcedir not in sys.path:
            sys.path.append(resourcedir)

        # we put resourcedir in PYTHONPATH in case we shell out or children
        # processes need this
        if PY3:
            if 'PYTHONPATH' in os.environ:
                if resourcedir not in os.environ['PYTHONPATH']:
                    os.environ['PYTHONPATH'] = os.environ['PYTHONPATH'] + os.pathsep + resourcedir
            else:
                os.environ['PYTHONPATH'] = resourcedir
        else:
            # Windows environment variables must be ascii encoded byte strings.
            if not isinstance(resourcedir, bytes):
                resourcedir = resourcedir.encode('ascii')
            if b'PYTHONPATH' in os.environ:
                if resourcedir not in os.environ[b'PYTHONPATH']:
                    os.environ[b'PYTHONPATH'] = os.environ[b'PYTHONPATH'] + os.pathsep + resourcedir
            else:
                os.environ[b'PYTHONPATH'] = resourcedir

    @property
    def data(self):
        warnings.warn(
            'data attribute has been deprecated, please access the data through input_file.file_data',
            DeprecationWarning
        )
        return self.input_file.file_data

    @property
    def pe(self):
        warnings.warn(
            'pe attribute has been deprecated, please access the pe through input_file.pe',
            DeprecationWarning
        )
        return self.input_file.pe

    @property
    def handle(self):
        warnings.warn(
            'handle attribute has been deprecated, please use input_file in a "with" context instead',
            DeprecationWarning
        )
        return self._handle

    @property
    def data(self):
        warnings.warn(
            'data attribute has been deprecated, please access the data through input_file.file_data',
            DeprecationWarning
        )
        return self.input_file.file_data

    @property
    def pe(self):
        warnings.warn(
            'pe attribute has been deprecated, please access the pe through input_file.pe',
            DeprecationWarning
        )
        return self.input_file.pe

    @property
    def handle(self):
        warnings.warn(
            'handle attribute has been deprecated, please use input_file in a "with" context instead',
            DeprecationWarning
        )
        return self._handle

    def filename(self):
        """
        Returns the filename of the input file. If input was not a filesystem object, we create a
        temp file that is cleaned up after parser is finished (unless tempcleanup is disabled)
        """
        warnings.warn(
            'filename() function has been deprecated, please access the filename through input_file.file_path',
            DeprecationWarning
        )
        # NOTE: "filename" is misleading. This function actually returns the full file path.
        return self.input_file.file_path

    def managed_tempdir(self):
        """
        Returns the filename of a managed temporary directory. This directory will be deleted when
        parser is finished, unless tempcleanup is disabled.
        """

        if not self.__managed_tempdir:
            self.__managed_tempdir = tempfile.mkdtemp(
                dir=self.tempdir, prefix="mwcp-managed_tempdir-")

            if self._disable_temp_cleanup:
                logger.info("Using managed temp dir: {}".format(self.__managed_tempdir))

        return self.__managed_tempdir

    def interpreter_path(self):
        """
        Returns the path for python interpreter, assuming it can be found. Because of various
        factors (including ability to override) this may not be accurate.

        """
        if not self._interpreter_path:
            # first try sys.executable--this is reliable most of the time but
            # doesn't work when python is embedded, ex. using wsgi mod for web
            # server
            if "python" in os.path.basename(sys.executable):
                self._interpreter_path = sys.executable
            # second try sys.prefix and common executable names
            else:
                possible_path = os.path.join(sys.prefix, "python.exe")
                if os.path.exists(possible_path):
                    self._interpreter_path = possible_path
                possible_path = os.path.join(sys.prefix, "bin", "python")
                if os.path.exists(possible_path):
                    self._interpreter_path = possible_path
            # other options to consider:
            # look at some library paths, such as os.__file__, use system path to find python
            # executable that uses that library use shell and let it find python. Ex. which python
        return self._interpreter_path

    def error(self, message):
        """
        Record an error message--typically only framework reports error and parsers report via debug
        """
        warnings.warn('This function is deprecated. Please use Python\'s built in logging framework '
                      'to log messages.', DeprecationWarning, 2)
        logger.error(message)

    def debug(self, message):
        """
        Record a debug message
        """
        warnings.warn('This function is deprecated. Please use Python\'s built in logging framework '
                      'to log messages.', DeprecationWarning, 2)
        # Even though reporter uses the name "debug".. This really is an INFO level debug message.
        logger.info(message)

    def _add_metatadata_listofstrings(self, key, value):
        if not value:
            logger.error("no values provided for {}, skipping".format(key))
            return
        value = convert_to_unicode(value)
        obj = self.metadata.setdefault(key, [])
        if self._disable_value_dedup or key == 'debug' or value not in obj:
            obj.append(value)

        if self._disable_auto_subfield_parsing:
            return

        if key == "filepath":
            # use ntpath instead of os.path so we are consistent across platforms. ntpath
            # should work for both windows and unix paths. os.path works for the platform
            # you are running on, not necessarily what the malware was written for.
            # Ex. when running mwcp on linux to process windows
            # malware, os.path will fail due to not handling
            # backslashes correctly.
            self.add_metadata("filename", ntpath.basename(value))
            self.add_metadata("directory", ntpath.dirname(value))

        if key == "c2_url":
            self.add_metadata("url", value)

        if key in ("c2_address", "proxy_address"):
            self.add_metadata("address", value)

        if key == "serviceimage":
            # we use tactic of looking for first .exe in value. This is
            # not guaranteed to be reliable
            if '.exe' in value:
                self.add_metadata("filepath", value[
                                  0:value.find('.exe') + 4])

        if key == "servicedll":
            self.add_metadata("filepath", value)

        if key == "ssl_cer_sha1":
            if not self.SHA1_RE.match(value):
                logger.error("Invalid SHA1 hash found: {!r}".format(value))

        if key in ("url", "c2_url"):
            # http://[fe80::20c:1234:5678:9abc]:80/badness
            # http://bad.com:80
            # ftp://127.0.0.1/really/bad?hostname=pwned
            match = self.URL_RE.search(value)
            if not match:
                logger.error("Error parsing as url: %s" % value)
                return

            if match.group("path"):
                self.add_metadata("urlpath", match.group("path"))

            if match.group("address"):
                address = match.group("address").rstrip(': ')
                if address.startswith("["):
                    # ipv6--something like
                    # [fe80::20c:1234:5678:9abc]:80
                    domain, found, port = address[1:].partition(']:')
                else:
                    domain, found, port = address.partition(":")

                if found:
                    if port:
                        if key == "c2_url":
                            self.add_metadata("c2_socketaddress", [domain, port, "tcp"])
                        else:
                            self.add_metadata("socketaddress", [domain, port, "tcp"])
                    else:
                        logger.error("Invalid URL {!r} found ':' at end without a port.".format(address))
                else:
                    if key == "c2_url":
                        self.add_metadata("c2_address", address)
                    else:
                        self.add_metadata("address", address)

    def _add_metadata_listofstringtuples(self, key, values):
        # Pad values that allow for shorter versions.
        expected_size = {
            'proxy': 5,
            'rsa_private_key': 8,
        }
        if key in expected_size:
            values = tuple(values) + ('',) * (expected_size[key] - len(values))

        values = list(map(convert_to_unicode, values))

        obj = self.metadata.setdefault(key, [])
        if self._disable_value_dedup or values not in obj:
            obj.append(values)

        if self._disable_auto_subfield_parsing:
            return

        # Add subfield components.
        subfield_map = {
            "registrypathdata": ["registrypath", "registrydata"],
            "service": ["servicename", "servicedisplayname", "servicedescription", "serviceimage", "servicedll"],
            "credential": ["username", "password"],
        }
        if key in subfield_map:
            subfields = subfield_map[key]
            for subfield, _value in zip(subfields, values):
                if _value:
                    self.add_metadata(subfield, _value)
            if len(values) != len(subfields):
                logger.error("Expected {} values in type {}, received {}".format(len(subfields), key, len(values)))

        # Special case validation.
        if key == "c2_socketaddress":
            self.add_metadata("socketaddress", values)
            self.add_metadata("c2_address", values[0])

        if key == "proxy_socketaddress":
            self.add_metadata("socketaddress", values)
            self.add_metadata("proxy_address", values[0])

        if key == "socketaddress":
            if len(values) != 3:
                logger.error(
                    "Expected three values in type socketaddress, received %i" % len(values))
            self.add_metadata("address", values[0])
            self.add_metadata("port", values[1:])

        if key in ("port", "listenport"):
            if len(values) != 2:
                logger.error("Expected two values in type %s, received %i" % (
                    key, len(values)))
            # check for integer number and valid proto?
            match = self.PORT_RE.search(values[0])
            if match:
                portnum = int(values[0])
                if portnum < 0 or portnum > 65535:
                    logger.error(
                        "Expected port to be number between 0 and 65535")
            else:
                logger.error(
                    "Expected port to be number between 0 and 65535")
            if len(values) >= 2:
                if values[1] not in ["tcp", "udp", "icmp"]:
                    logger.error(
                        "Expected port type to be tcp or udp (or icmp)")

        if key == "proxy":
            if len(values) != 5:
                logger.error("Expected 5 values in type %s, received %i" % (key, len(values)))
            self.add_metadata("credential", values[:2])
            if len(values[2:]) == 1:
                self.add_metadata("proxy_address", values[2])
            else:
                self.add_metadata("proxy_socketaddress", values[2:])

        if key == "ftp":
            if len(values) != 3:
                logger.error("Expected 3 values in type %s, received %i" % (key, len(values)))
            self.add_metadata("credential", values[:2])
            if len(values) >= 3:
                self.add_metadata("url", values[2])

        if key == "rsa_public_key":
            if len(values) != 2:
                logger.error("Expected 3 values in type %s, received %i" % (key, len(values)))

        if key == "rsa_private_key":
            if len(values) != 8:
                logger.error("Expected 8 values in type %s, received %i" % (key, len(values)))

    def _add_metadata_dictofstrings(self, key, value):
        # check for type of other?
        for subkey, subvalue in value.items():
            if isinstance(subvalue, (bytes, str)):
                subkey = convert_to_unicode(subkey)
                subvalue = convert_to_unicode(subvalue)
                # CAPE: modified to improve display for 'other' key/value pairs
                obj = self.metadata.setdefault(subkey, [])
                if subvalue not in obj:
                    obj.append(subvalue)
            else:
                # TODO: support inserts of lists (assuming members are strings)?
                logger.error("Could not add object of %s to metadata under other using key %s" % (
                    str(type(subvalue[subkey])), subkey))

    def add_metadata(self, key, value):
        """
        Report a metadata item

        Primary method to report metadata as a result of parsing.

        Args:
            key: string specifying the key of the metadata. Should be one of values specified in fields.json.
            value: string specifying the value of the metadata. Should be a utf-8 encoded string or a unicode object.

        """
        keyu = convert_to_unicode(key)
        if not value or all(not _value for _value in value):
            logger.warn("no values provided for %s, skipping" % key)
            return

        if keyu not in self.fields:
            raise KeyError('Invalid field name: {}'.format(keyu))

        fieldtype = self.fields[keyu]['type']

        try:
            if fieldtype == "listofstrings":
                self._add_metatadata_listofstrings(keyu, value)

            if fieldtype == "listofstringtuples":
                self._add_metadata_listofstringtuples(keyu, value)

            if fieldtype == "dictofstrings":
                self._add_metadata_dictofstrings(keyu, value)
        except Exception:
            logger.exception("Error adding metadata for key: {}".format(keyu))

    def run_parser(self, name, file_path=None, data=b"", **kwargs):
        """
        Runs specified parser on file

        :param str name: name of parser module to run (use ":" notation to specify source if necessary e.g. "mwcp-acme:Foo")
        :param str file_path: file to parse
        :param bytes data: use data as file instead of loading data from filename
        """
        self.__reset()

        if file_path:
            with open(file_path, 'rb') as f:
                self.input_file = mwcp.FileObject(
                    f.read(), self, file_name=os.path.basename(file_path), output_file=False)
                self.input_file.file_path = file_path
        else:
            self.input_file = mwcp.FileObject(data, self, output_file=False)

        try:
            with self.__redirect_stdout():
                found = False
                for parser_name, source, parser_class in mwcp.iter_parsers(name):
                    found = True
                    with self.input_file as fo:
                        self._handle = fo
                        try:
                            parser = parser_class(reporter=self)
                            parser.run(**kwargs)
                        except (Exception, SystemExit) as e:
                            if file_path:
                                identifier = file_path
                            else:
                                identifier = hashlib.md5(data).hexdigest()
                            logger.exception("Error running parser {}:{} on {}".format(
                                source, parser_name, identifier))

                if not found:
                    logger.error('Could not find parsers with name: {}'.format(name))
        finally:
            self.__cleanup()

    def output_file(self, data, filename, description=''):
        """
        Report a file created by the parser

        This should involve a file created by the parser and related to the malware.

        :param bytes data: The contents of the output file
        :param str filename: filename (basename) of file
        :param str description: description of the file
        """
        md5 = hashlib.md5(data).hexdigest()

        # TODO: Add filename sanitization.

        # Rename file if we have a name collision.
        num_char = 5
        orig_filename = filename
        while filename in self.outputfiles:
            if md5 == self.outputfiles[filename]['md5']:
                logger.info('Ignoring duplicate output file: {}'.format(filename))
                return
            assert num_char <= 32  # We shouldn't get into an infinite loop due to the check above.
            filename = orig_filename + '_' + md5[:num_char]
            num_char += 1
        if orig_filename != filename:
            logger.info('Renamed {} to {}'.format(orig_filename, filename))

        basename = os.path.basename(filename)
        self.outputfiles[filename] = {
            'data': data, 'description': description, 'md5': md5}

        if self._base64_output_files:
            self.add_metadata(
                "outputfile", [basename, description, md5, base64.b64encode(data)])
        else:
            self.add_metadata("outputfile", [basename, description, md5])

        if self._disable_output_files:
            return

        if self.__outputfile_prefix:
            if self.__outputfile_prefix == "md5":
                fullpath = os.path.join(self.__outputdir, "%s_%s" % (
                    binascii.hexlify(self.input_file.md5).decode('utf8'), basename))
            else:
                fullpath = os.path.join(self.__outputdir, "%s_%s" % (
                    self.__outputfile_prefix, basename))
        else:
            fullpath = os.path.join(self.__outputdir, basename)

        try:
            with open(fullpath, "wb") as f:
                f.write(data)
            logger.info("Output file: %s" % (fullpath))
            self.outputfiles[filename]['path'] = fullpath
        except Exception as e:
            logger.error("Failed to write output file: %s, %s" % (fullpath, str(e)))

    def report_tempfile(self, filename, description=''):
        """
        load filename from filesystem and report using output_file
        """
        if os.path.isfile(filename):
            with open(filename, "rb") as f:
                data = f.read()
            self.output_file(data, os.path.basename(filename), description)
        else:
            logger.info(
                "Could not output file because it could not be found: %s" % filename)

    def format_list(self, values, key=None):

        if key == "credential" and len(values) == 2:
            return "%s:%s" % (values[0], values[1])
        elif key == "outputfile" and len(values) >= 3:
            return "%s %s" % (values[0], values[1])
        elif key in ("port", "listenport") and len(values) == 2:
            return "%s/%s" % (values[0], values[1])
        elif key == "registrykeyvalue" and len(values) == 2:
            return "%s=%s" % (values[0], values[1])
        elif key in ("socketaddress", "c2_socketaddress", "proxy_socketaddress") and len(values) == 3:
            return "%s:%s/%s" % (values[0], values[1], values[2])
        elif key == "service" and len(values) == 5:
            return ", ".join(values)
        else:
            return ' '.join(values)

    def print_keyvalue(self, key, value):
        print(self.get_printable_key_value(key, value))

    def print_report(self):
        """
        Output in human readable report format
        """
        print(self.get_output_text())

    def get_printable_key_value(self, key, value):
        output = ""
        printkey = key

        if isinstance(value, (str, bytes)):
            output += "{:20} {}\n".format(printkey, convert_to_unicode(value))
        else:
            for item in value:
                if isinstance(item, (str, bytes)):
                    output += "{:20} {}\n".format(printkey, convert_to_unicode(item))
                else:
                    output += "{:20} {}\n".format(printkey, self.format_list(item, key=key))
                printkey = ""

        return output

    def get_output_text(self):
        """
        Get data in human readable report format.
        """

        output = ""
        infoorderlist = INFO_FIELD_ORDER
        fieldorderlist = STANDARD_FIELD_ORDER

        if 'inputfilename' in self.metadata:
            output += "\n----File Information----\n\n"
            for key in infoorderlist:
                if key in self.metadata:
                    output += self.get_printable_key_value(
                        key, self.metadata[key])

        output += "\n----Standard Metadata----\n\n"

        for key in fieldorderlist:
            if key in self.metadata:
                output += self.get_printable_key_value(key, self.metadata[key])

        # in case we have additional fields in fields.json but the order is not
        # updated
        for key in self.metadata:
            if key not in fieldorderlist and key not in ["other", "debug", "outputfile"] and key in self.fields:
                output += self.get_printable_key_value(key, self.metadata[key])

        if "other" in self.metadata:
            output += "\n----Other Metadata----\n\n"
            for key in sorted(list(self.metadata["other"])):
                output += self.get_printable_key_value(
                    key, self.metadata["other"][key])

        if "debug" in self.metadata:
            output += "\n----Debug----\n\n"
            for item in self.metadata["debug"]:
                output += "{}\n".format(item)

        if "outputfile" in self.metadata:
            output += "\n----Output Files----\n\n"
            for value in self.metadata["outputfile"]:
                output += self.get_printable_key_value(
                    value[0], (value[1], value[2]))

        if self.errors:
            output += "\n----Errors----\n\n"
            for item in self.errors:
                output += "{}\n".format(item)

        return output

    @contextlib.contextmanager
    def __redirect_stdout(self):
        """Redirects stdout temporarily to the logger."""
        class _LogWriter(object):
            def write(self, message):
                logger.info(message)
            def flush(self):
                pass
        orig_stdout = sys.stdout
        sys.stdout = _LogWriter()
        try:
            yield
        finally:
            sys.stdout = orig_stdout

    def __reset(self):
        """
        Reset all the data in the reporter object that is set during the run_parser function

        Goal is to make the reporter safe to use for multiple run_parser instances
        """
        self.__managed_tempdir = None
        self.input_file = None
        self._handle = None

        self.metadata = {}
        self.outputfiles = {}
        self.errors = []

        # To keep backwards compatibility, setup log handler to add errors and debug messages to reporter.
        # TODO: Remove this when the Reporter object should no longer be responsible for logging.
        log_handler = ReporterLogHandler(self)
        logging.root.addHandler(log_handler)
        # Setup a simple format that doesn't contain any runtime variables.
        log_handler.addFilter(logutil.LevelCharFilter())
        log_handler.setFormatter(logging.Formatter("[%(level_char)s] %(message)s"))
        self._log_handler = log_handler

    def __cleanup(self):
        """
        Cleanup things
        """
        # Remove log handler.
        if self._log_handler:
            logging.root.removeHandler(self._log_handler)
            self._log_handler = None

        # Delete temporary directory.
        if not self._disable_temp_cleanup:
            if self.__managed_tempdir:
                try:
                    shutil.rmtree(self.__managed_tempdir, ignore_errors=True)
                except Exception as e:
                    logger.error("Failed to purge temp dir: %s, %s" %
                               (self.__managed_tempdir, str(e)))
                self.__managed_tempdir = ''

        self.__managed_tempdir = None

    def __del__(self):
        self.__cleanup()
